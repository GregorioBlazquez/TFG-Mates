{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Explicaciones previas](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación comento brevemente algunos conceptos que se han usado en esta parte y que pueden ser interesantes para entender mejor este proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Explicaciones previas](#toc1_)    \n",
    "  - [Random forest](#toc1_1_)    \n",
    "  - [Importancia de Características en un Random Forest para Regresión](#toc1_2_)    \n",
    "  - [Permutation Feature Importance](#toc1_3_)    \n",
    "  - [Partial Dependence Plot (PDP)](#toc1_4_)    \n",
    "  - [Base de datos usada](#toc1_5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Random forest](#toc0_)\n",
    "\n",
    "Un **Random Forest** es un poderoso algoritmo de aprendizaje automático utilizado tanto para clasificación como para regresión. Se basa en la combinación de múltiples árboles de decisión para mejorar la precisión y controlar el sobreajuste.\n",
    "\n",
    "**Componentes Clave**:\n",
    "\n",
    "1. **Árboles de Decisión**: Un árbol de decisión es un modelo predictivo que toma decisiones basadas en reglas aprendidas a partir de los datos de entrenamiento. Cada árbol en el Random Forest se entrena de manera independiente.\n",
    "\n",
    "2. **Bootstrap Aggregating (Bagging)**: Para construir el bosque, se utilizan diferentes muestras del conjunto de datos de entrenamiento con reemplazo (bootstrap). Esto significa que cada árbol se entrena con una muestra diferente del conjunto de datos.\n",
    "\n",
    "3. **Selección Aleatoria de Características**: En cada nodo de un árbol de decisión, en lugar de considerar todas las características posibles para dividir los datos, el algoritmo selecciona aleatoriamente un subconjunto de características. Esto introduce diversidad adicional en los árboles.\n",
    "\n",
    "4. **Promediado de Resultados**: Para realizar una predicción, el Random Forest promedia (en el caso de regresión) o toma el voto mayoritario (en el caso de clasificación) de las predicciones realizadas por todos los árboles del bosque.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "1. **Mejora de la Precisión**: Al combinar múltiples árboles, el Random Forest suele lograr una mayor precisión que los árboles individuales.\n",
    "\n",
    "2. **Reducción del Sobreajuste**: La técnica de bagging y la selección aleatoria de características ayudan a reducir el riesgo de sobreajuste, haciendo el modelo más robusto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostramos un esquema de la estructura y funcionamiento de un Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagen](Imagenes/RandomForest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Importancia de Características en un Random Forest para Regresión](#toc0_)\n",
    "\n",
    "La importancia de características (**feature importance**) en un modelo de Random Forest para regresión es una métrica que indica la relevancia de cada característica en la predicción del modelo. Este valor se calcula durante el proceso de entrenamiento del Random Forest y se basa en la reducción de la varianza atribuible a cada característica.\n",
    "\n",
    "**¿Cómo se calcula?**\n",
    "\n",
    "1. **Construcción de Árboles**: Un Random Forest está compuesto por múltiples árboles de decisión. Cada árbol se entrena utilizando diferentes subconjuntos del conjunto de datos originales.\n",
    "\n",
    "2. **Reducción de Impureza**: Durante el entrenamiento, cada árbol decide las divisiones (splits) basándose en características individuales para minimizar la impureza (usualmente medida por criterios como el MSE - Mean Squared Error en regresión).\n",
    "\n",
    "3. **Acumulación de Importancia**: La importancia de cada característica se acumula a lo largo de todas las divisiones en todos los árboles del bosque. En cada división, se registra cuánto se ha reducido la impureza del modelo debido a la característica seleccionada para esa división.\n",
    "\n",
    "4. **Promedio y Normalización**: Las reducciones de impureza acumuladas para cada característica se promedian y, frecuentemente, se normalizan para que la suma de todas las importancias sea 1 (o 100%).\n",
    "\n",
    "**Interpretación**\n",
    "\n",
    "1. **Valores más altos**: Las características con valores de importancia más altos tienen un mayor impacto en la predicción del modelo.\n",
    "\n",
    "2. **Selección de Características**: Se pueden utilizar estas importancias para realizar selección de características, eliminando aquellas que tienen baja o nula importancia para simplificar el modelo sin sacrificar mucho rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra un esquema del funcionamiento de este método:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/FeatureImportance1.png\" alt=\"Imagen\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetiríamos esto para todos los caminos y acumularíamos los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/FeatureImportance2.png\" alt=\"Imagen\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Permutation Feature Importance](#toc0_)\n",
    "La Importancia de Característica por Permutación (**Permutation Feature Importance**) es una técnica utilizada para evaluar la importancia de las características en un modelo de machine learning. Funciona midiendo cuánto cambia la **métrica de rendimiento** del modelo cuando los valores de una característica específica se barajan de manera aleatoria, mientras se mantienen fijos los valores de todas las demás características. En otras palabras, mide el **impacto de cada característica en el rendimiento del modelo al perturbarla**.\n",
    "\n",
    "En el contexto de un **modelo de regresión**, la Permutation Feature Importance se interpreta de la siguiente manera:\n",
    "\n",
    "1. **Métrica de Rendimiento Base**: Primero, se calcula la métrica de rendimiento del modelo utilizando las características en su estado original. En regresión, esta métrica de rendimiento suele ser el error cuadrático medio (Mean Squared Error, MSE), el error absoluto medio (Mean Absolute Error, MAE) o el coeficiente de determinación (R²).\n",
    "\n",
    "2. **Perturbación de la Característica**: Luego, se selecciona una característica y se barajan sus valores aleatoriamente en el conjunto de datos, de manera que se rompe la relación entre esta característica y la variable objetivo.\n",
    "\n",
    "3. **Recalculo de la Métrica**: Se vuelve a calcular la métrica de rendimiento del modelo utilizando el conjunto de datos con la característica perturbada.\n",
    "\n",
    "4. **Cambio en la Métrica de Rendimiento**: La importancia de la característica se determina midiendo la diferencia entre la métrica de rendimiento original y la métrica de rendimiento con la característica perturbada. Si la perturbación de una característica específica causa un gran deterioro en la métrica de rendimiento del modelo, se considera que esa característica es importante.\n",
    "\n",
    "**Interpretación de los Valores**\n",
    "\n",
    "- **Valor Alto de Importancia**: Si la perturbación de una característica lleva a un gran aumento en el MSE (o un gran aumento en MAE, o una gran disminución en R²), significa que la característica es importante para el modelo. Esto indica que la característica tiene una relación significativa con la variable objetivo y su información es crucial para hacer predicciones precisas.\n",
    "\n",
    "- **Valor Bajo de Importancia**: Si la perturbación de una característica lleva a un cambio pequeño o nulo en la métrica de rendimiento del modelo, significa que la característica tiene poca importancia. Esto sugiere que la característica no aporta mucha información relevante para las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra un esquema del funcionamiento de PFI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagen](Imagenes/Permutation_Feature_Importance_Graphic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Partial Dependence Plot (PDP)](#toc0_)\n",
    "\n",
    "**Partial Dependence Plot (PDP)** es una representación gráfica que describe la relación entre una o más variables de entrada y la variable de respuesta en un modelo de regresión. Ayuda a entender cómo una variable o conjunto de variables independientes influyen en la predicción del modelo mientras se mantienen constantes las demás variables.\n",
    "\n",
    "Las siguientes fórmulas describen el calculo teórico y la estimación de la **función de dependencia parcial**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagen](Imagenes/PDP_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagen](Imagenes/PDP_estimation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Base de datos usada](#toc0_)\n",
    "La idea del el modelo que vamos a usar es predecir datos que faltan en la base de datos, más específicamente es un problema de regresión. Queremos completar valores faltantes para poder predecir el gasto total de clientes, siendo el total la suma de las tres variables que nos interesan predecir. Por motivos de complejidad vamos a estudiar tres modelos con un único valor faltante por cada uno. \n",
    "\n",
    "A continuación se van a comentar el significado de las variables, pero primero debemos comentar que en la base de datos original podía haber varias entradas para un mismo cliente, por eso variables como el estado civil pueden estar representadas como la mediana de los diferentes registros que se tienen. Las variables como préstamos o gastos se obtienen como la suma de las diferentes entradas.\n",
    "\n",
    "Las variables con las que vamos a trabajar son las siguientes:\n",
    "- **prest**: cantidad en préstamo.\n",
    "- **cirbe**: esta variable representa un informe del Banco Central de España.\n",
    "- **finan**: financiación.\n",
    "- **entradas_dinero**: esta variable representa las entradas de dinero de un cliente.\n",
    "- **edad**: del cliente.\n",
    "- **antiguedad**: del cliente.\n",
    "- **norm_total_gastos**: gastos conocidos totales del cliente normalizados.\n",
    "- **e_civil_median**: el cliente puede ser un conjunto de personas, se coge la mediana del estado civil representado numéricamente.\n",
    "- **provincia_median**: la mediana de los datos que se tienen para la provincia del cliente. \n",
    "- **ccaa_median**: la mediana de los datos que se tienen para la comunidad autónoma del cliente. \n",
    "- **aut**: si es autónomo.\n",
    "- **with_dom**: si tiene nómina domiciliada.\n",
    "- **cirbe_nan**: si no tiene el informe CIRBE o no (en cuyo caso cirbe vale 0).\n",
    "\n",
    "Las variables que vamos a predecir son las siguientes:\n",
    "- **recibos**: gastos en recibos.\n",
    "- **tarj**: gastos en tarjeta.\n",
    "- **impuestos**: gastos en impuestos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
